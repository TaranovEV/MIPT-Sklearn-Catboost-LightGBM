{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, \\\n",
    "    GaussianNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, \\\n",
    "    KBinsDiscretizer, OrdinalEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Домашнее задание 5</font>\n",
    "\n",
    "### Упражнение 1. Kernel trick\n",
    "\n",
    "Используйте kernel trick, который позволит логистической регрессии достигнуть точности не менее $85\\%$. Максимальная точность, которой можно добиться, $\\approx 90\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/spiral/train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/spiral/test.csv'\n",
    "train_df = pd.read_csv(train_url)\n",
    "test_df = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посмотрим на визуальное представление данных, тобы понять каким образом разделять\n",
    "class_0 = train_df[train_df['class']==0]\n",
    "class_1 = train_df[train_df['class']==1]\n",
    "class_2 = train_df[train_df['class']==2]\n",
    "plt.scatter(class_0['x'], class_0['y'], color='blue', s=1,label = 'class_0')\n",
    "plt.scatter(class_1['x'], class_1['y'], color='red', s=1,label = 'class_1')\n",
    "plt.scatter(class_2['x'], class_2['y'], color='green', s=1,label = 'class_2')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "#объединим данные для очистки и преобразования\n",
    "new_data = pd.concat([train_df, test_df])\n",
    "X = new_data.drop(['Unnamed: 0','class'], axis=1)\n",
    "y = new_data['class']\n",
    "#преобразовывать будем с посощью RBFSampler\n",
    "rbf_feature = RBFSampler(random_state=1)\n",
    "transform = rbf_feature.fit_transform(X)\n",
    "clf = Pipeline(steps=[('preprocessor', rbf_feature),\n",
    "                    ('classifier', LogisticRegression(multi_class='auto'))])\n",
    "param_grid = {'classifier__solver': ['newton-cg',\n",
    "                                     'liblinear','sag','saga','lbfgs'],\n",
    "             'classifier__C':np.linspace(1,10,50),\n",
    "             'preprocessor__gamma':np.linspace(2,5,50)\n",
    "             }\n",
    "X_train, X_test, y_train, y_test = train_test_split(transform, y, test_size=0.2)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)#,verbose=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print((\"best score from grid search: %.3f\"\n",
    "                   % grid_search.score(X_test, y_test)))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добился результатов :best score from grid search: 0.854\n",
    "{'classifier__C': 6.327, 'classifier__solver': 'sag', 'preprocessor__gamma': 2.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 2. Наивный байесовский классификатор\n",
    "\n",
    "В библиотеке Sklearn есть \n",
    "\n",
    "- класс [`GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) для признаков, распределенных по Гауссу;\n",
    "\n",
    "- класс [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) для призкаков, подчиняющихся мультиномиальному распределению;\n",
    "\n",
    "- класс [`BernoulliNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB), который рассматривает каждый признак, как распределенный по Бернулли;\n",
    "\n",
    "- класс [`CategoricalNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB) для классических категориальных признаков (значение признака не счетчик, как в классификации спама, а какой-то элемент неупорядоченного множества, например {Екатеринбург, Москва, Санкт-Петербург}).\n",
    "\n",
    "Примените к датасету [Heart](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29) наивный байесовский классификатор. Для этого выберите подходящую модель  из перечисленных выше. В датасете есть категориальные и числовые признаки. Есть 2 способа комбинировать числовые признаки с категориальными:\n",
    "\n",
    "- дискретизация числовых признаков,\n",
    "\n",
    "- объединенеие гауссовского классификатора для числовых признаков с дискретной моделью для категориальных признаков.\n",
    "\n",
    "Второй подход работает так:\n",
    "\n",
    "- обучаются 2 классификатора &mdash; один на категориальных признаках, а другой &mdash; на числовых,\n",
    "\n",
    "- параметры обоих классификаторов (условные вероятности признаков) используются для предсказания.\n",
    "\n",
    "Второй подход можно применять для объединения любых байесовских классификаторов. Например, если часть признаков подчиняется мультиномиаольному распределению, а часть распределению Бернулли.\n",
    "\n",
    "Сравните эффективность методов в задаче классификации на датасете Heart.\n",
    "\n",
    ">Используя методы и атрибуты классов `sklearn`, можно объединить модели по крайней мере 2мя способоами. Любое решение в предположении, что признаки условно независимы, засчитывается.\n",
    "\n",
    ">При решении задачи могут пригодиться классы [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html), [`KBinsDiscretizer`](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html#sphx-glr-auto-examples-preprocessing-plot-discretization-py). Рекомендуется использовать [пайплайны](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), включающие саму модель, дискретизацию, нормализацию или другие подготовительные действия. Чтобы индивидуально работать с признаками разных типов в рамках пайплайна, подойдет [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). К моделям на основе классов `Pipeline` и `ColumnTransformer` можно [применять](https://scikit-learn.org/stable/modules/compose.html#pipeline-nested-parameters) `GridSearch`.\n",
    "\n",
    ">Код для скачивания датасета внизу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/heart_disease/train.csv'\n",
    "train_df = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/heart_disease/test.csv'\n",
    "test_df = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_indices = [1, 2, 5, 6, 8, 10, 11, 12]\n",
    "numerical_indices = [0, 3, 4, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = []\n",
    "for i in numerical_indices:\n",
    "    numerical.append(train_df.columns[i])\n",
    "\n",
    "categorical = []\n",
    "for i in categorical_indices:\n",
    "    categorical.append(train_df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подготовим данные для подбора оптимальной модели описывающей распределение числовых признаков\n",
    "train_X = train_df.drop(['class'], axis=1)\n",
    "train_y = train_df['class']\n",
    "test_X = test_df.drop(['class'], axis=1)\n",
    "test_y = test_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Набор количественных признаков:': ['age', 'cholestoral', 'heart rate', 'oldpeak'], 'Нормализатор': StandardScaler(copy=True, with_mean=True, with_std=True), 'Модель:': 'BernoulliNB()', 'test_data_score:': 0.7777777777777778}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import combinations\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, \\\n",
    "    RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, \\\n",
    "    GaussianNB, BernoulliNB\n",
    "import re\n",
    "\n",
    "#создадим список лучших параметров\n",
    "dict_of_best_params = {'Набор количественных признаков:':0,'Нормализатор':0,\n",
    "                              'Модель:':0,'test_data_score:':int(0)}\n",
    "scalers =  [\"MinMaxScaler\" ,\"StandardScaler\", \"RobustScaler\", \n",
    "            \"QuantileTransformer\", \"PowerTransformer\"]\n",
    "\n",
    "#создадим список комбинаций числовых признаков для выбора модели\n",
    "#комбинации включают в себя все возможные начиная от одного признака \n",
    "res = []\n",
    "for sub in range(7):\n",
    "    res.extend(combinations(numerical, sub + 1))\n",
    "for i in res:\n",
    "    i = re.sub('[\\\\()[\\\\]\\'\"]', str(i))\n",
    "    men = []\n",
    "#долго мучался с лишними кавычками-лучше этого решения не придумал\n",
    "    number_step = 0\n",
    "    for el in lst:\n",
    "        \n",
    "        el = el.rstrip('\\'').lstrip('\\'').rstrip('\\\"').lstrip('\\\"').lstrip(' ')\n",
    "        men.append(el)\n",
    "\n",
    "        for scaler in scalers:\n",
    "            if scaler==\"MinMaxScaler\":\n",
    "                num_transformer = MinMaxScaler()\n",
    "            elif scaler==\"StandardScaler\":\n",
    "                num_transformer = StandardScaler()\n",
    "            elif scaler==\"RobustScaler\":\n",
    "                num_transformer = RobustScaler()\n",
    "            elif scaler==\"QuantileTransformer\":\n",
    "                num_transformer = QuantileTransformer(output_distribution='normal')\n",
    "            else:\n",
    "                num_transformer = PowerTransformer('yeo-johnson')\n",
    "\n",
    "#примемяем ColumnTransformer               \n",
    "            preprocessor_for_num = ColumnTransformer([('num',num_transformer, men)])\n",
    "#создаем список моделей для последующего обхода этого списка в цикле    \n",
    "            classifier = ['GaussianNB()','MultinomialNB()','BernoulliNB()']\n",
    "#для каждого по очередно               \n",
    "            for clf in classifier:\n",
    "#применяется Pipeline первый шаг в котором предобработка(нормализация), второй-само обучение\n",
    "                if clf=='GaussianNB()':\n",
    "                    num_classification = \\\n",
    "                    Pipeline(steps=[('num_preprocessor', preprocessor_for_num),\n",
    "                               ('GaussianNB()', GaussianNB())])\n",
    "                elif clf=='MultinomialNB()':\n",
    "                    num_classification = \\\n",
    "                    Pipeline(steps=[('num_preprocessor', preprocessor_for_num),\n",
    "                               ('MultinomialNB()', MultinomialNB())])\n",
    "                elif clf=='BernoulliNB()':\n",
    "                    num_classification = \\\n",
    "                    Pipeline(steps=[('num_preprocessor', preprocessor_for_num),\n",
    "                               ('BernoulliNB()', BernoulliNB())])\n",
    "#в процессе обучения выяснилос, что при применении MultinomialNB() если есть отрицательные значения\n",
    "#вылетает ошибка ValueError Negative values in data passed to MultinomialNB (input X)\n",
    "#обходим ее через обработку исключений\n",
    "                try:\n",
    "                    num_classification.fit(train_X, train_y)\n",
    "                    score = num_classification.score(test_X, test_y)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "#далее обновляем значения в словаре-по условию что каждый последующий score(test_X, test_y)\n",
    "#сравнивается с предыдущим по принципу-если больше, то максимален\n",
    "                if dict_of_best_params[\"test_data_score:\"]<=score:\n",
    "                    dict_of_best_params[\"test_data_score:\"]=score\n",
    "                    dict_of_best_params['Модель:']=clf\n",
    "                    dict_of_best_params['Нормализатор']=num_transformer   \n",
    "                    dict_of_best_params['Набор количественных признаков:']=men\n",
    "            number_step+=1\n",
    "#выводим на печать лучшие параметры    \n",
    "print(dict_of_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь подготовим данные для объединения моделей\n",
    "new_data = pd.concat([train_df, test_df])\n",
    "X = new_data.drop(['class'], axis=1)\n",
    "y = new_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 (+/- 0.04) [StackingCVClassifier]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "#для категориальных будем использовать OrdinalEncoder()\n",
    "categorial_transformer = OrdinalEncoder()\n",
    "preprocessor_for_cat = ColumnTransformer(\n",
    "    [('cat', categorial_transformer,categorical)])\n",
    "cat_transform = preprocessor_for_cat.fit_transform(X)\n",
    "#заменим в датасете на категориальные признаки после трансформации\n",
    "for i in range(0,8):\n",
    "    X[categorical[i]] = cat_transform[:,i]\n",
    "#из предыдущей ячейки возмем лучшие полученнные значения для числовых признаков \n",
    "num_transformer = StandardScaler()\n",
    "numerical = ['age', 'cholestoral', 'heart rate', 'oldpeak']\n",
    "preprocessor_for_cat = ColumnTransformer(\n",
    "    [('num', num_transformer,numerical)])\n",
    "num_transform = preprocessor_for_cat.fit_transform(X)\n",
    "#заменим в датасете на числовые признаки после трансформации\n",
    "for i in range(0,4):\n",
    "    X[numerical[i]] = num_transform[:,i]\n",
    "clf_cat = CategoricalNB()\n",
    "clf_num = BernoulliNB()\n",
    "#первый pipeline для категориальных, второй для числовых\n",
    "pipe1 = make_pipeline(ColumnSelector(cols=categorical),\n",
    "                      CategoricalNB())\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=numerical),\n",
    "                      BernoulliNB())\n",
    "# объединяем pipeline \n",
    "sclf = StackingCVClassifier(classifiers=[pipe1, pipe2], \n",
    "                            meta_classifier=GaussianNB(),\n",
    "                            use_probas=True,random_state=42)\n",
    "\n",
    "scores = model_selection.cross_val_score(sclf, X, y, \n",
    "                                              cv=5, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), 'StackingCVClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение 3\n",
    "\n",
    "1. Попробуйте разные способы работы с недостающими признаками: удаление, присвоение наиболее правдоподобного значения, введение новой категории `'<UNK>'` для недостающих признаков.\n",
    "\n",
    "- Попробуйте разные методы подготовки признаков.\n",
    "\n",
    "- Примените SVM к датасету [Adult](https://archive.ics.uci.edu/ml/datasets/Adult), попробуйте все доступные ядра, подберите для них параметры.\n",
    "\n",
    "- Подберите лучшую модель для датасета Adult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/adult/train.csv'\n",
    "train_df = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://raw.githubusercontent.com/PeganovAnton/ml-datasets/master/adult/test.csv'\n",
    "test_df = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заменим целевой признак на булевые значения\n",
    "#больше 50К-1,меньше либо равно- 0\n",
    "train_df['class'] = (train_df['class'] == '>50K').astype(int)\n",
    "test_df['class'] = (test_df['class'] == '>50K').astype(int)\n",
    "#объединяем датасет для удобства кодирования\n",
    "new_data = pd.concat([train_df, test_df])\n",
    "new_data = new_data.drop([19609])\n",
    "X = new_data.drop(['class'], axis=1)\n",
    "y = new_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вычисления приходят долго, поэтому решил немного сэкономить на памяти\n",
    "#переведем тип object в category\n",
    "#копируем фрейм\n",
    "copy_data = new_data.copy()\n",
    "#создаем пустой датафрейм\n",
    "converted_data = pd.DataFrame()\n",
    "#пишем цикл, который перебирает каждый столбец object,\n",
    "#проверяет его на соответствие заданному порогу\n",
    "#(количество уникальных значений должно быть меньше 50%\n",
    "#от общего количества значений) и, если столбец \n",
    "#удовлетворяет порогу, преобразовывает его в тип category\n",
    "for col in copy_data.columns:\n",
    "    num_unique_values = len(copy_data[col].unique())\n",
    "    num_total_values = len(copy_data[col])\n",
    "    if num_unique_values / num_total_values < 0.5:\n",
    "        converted_data.loc[:,col] = copy_data[col].astype('category')\n",
    "    else:\n",
    "        converted_data.loc[:,col] = copy_data[col]\n",
    "#делим признаки на категориальные и числовые\n",
    "categorical_indices = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "numerical_indices = [0, 2, 4, 10, 11, 12]\n",
    "numerical = []\n",
    "for i in numerical_indices:\n",
    "    numerical.append(train_df.columns[i])\n",
    "\n",
    "categorical = []\n",
    "for i in categorical_indices:\n",
    "    categorical.append(train_df.columns[i])\n",
    "not_full_feats = []\n",
    "n_a_indices = [1, 6, 13]\n",
    "for i in n_a_indices:\n",
    "    not_full_feats.append(train_df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import category_encoders\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, \\\n",
    "    RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#создаем список нормализаторов, список кодировщиков\n",
    "scalers =  [\"MinMaxScaler\" ,\"StandardScaler\", \"RobustScaler\", \\\n",
    "            \"QuantileTransformer\", \"PowerTransformer\"]\n",
    "encoders = ['OneHotEncoder()' ,'category_encoders.woe.WOEEncoder()']\n",
    "#список видов предобработки \n",
    "#drop_na_feats-удаление признаков с пропусками\n",
    "#replace_na_unk-замена ? на '<UNK>'\n",
    "steps_data_preprocessing = ['drop_na_feats', 'replace_na_unk']\n",
    "\n",
    "#словарь для хранения лучших параметров \n",
    "dict_of_best_params = {'Preproccess_data:':0,'Category_encoder:':0,\n",
    "                       'Scaler:':0,'Kernel:':0,\n",
    "                        'test_data_score:':int(0)}\n",
    "#по очереди перебираем виды предобработки\n",
    "for step in steps_data_preprocessing:\n",
    "    if step=='drop_na_feats':\n",
    "        mod_X = converted_data.drop(['class'], axis=1)\n",
    "        mod_X = mod_X.drop(not_full_feats, axis=1)\n",
    "        categorical = [ 'education', 'marital_status', \n",
    "                       'relationship', 'race', 'sex']\n",
    "    else:\n",
    "        for feat in not_full_feats:\n",
    "            mod_X = converted_data.drop(['class'], axis=1)\n",
    "            mod_X[feat] = np.where(mod_X[feat] == '?', '<UNK>', mod_X[feat])\n",
    "            categorical = ['workclass','education','marital_status',\n",
    "                           'occupation','relationship','race','sex','native-country']\n",
    "#далее по очереди перебираем нормализаторы и категориальные энкодеры\n",
    "    for encoder in encoders:\n",
    "        if encoder=='OneHotEncoder()' :\n",
    "            pipe1 =  OneHotEncoder()\n",
    "        else:\n",
    "            pipe1 =  category_encoders.woe.WOEEncoder()\n",
    "        for scaler in scalers:\n",
    "            if scaler==\"MinMaxScaler\":\n",
    "                pipe2 = MinMaxScaler()\n",
    "            elif scaler==\"StandardScaler\":\n",
    "                pipe2 = StandardScaler()\n",
    "            elif scaler==\"RobustScaler\":\n",
    "                pipe2 = RobustScaler()\n",
    "            elif scaler==\"QuantileTransformer\":\n",
    "                pipe2 = QuantileTransformer(output_distribution='normal')\n",
    "            else:\n",
    "                pipe2 = PowerTransformer('yeo-johnson')\n",
    "#применяем ColumnTransformer \n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', pipe2, numerical),\n",
    "                    ('cat', pipe1, categorical)])\n",
    "#пайплайн для предобработки и последующей передачи в RandomizedSearchCV\n",
    "            clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('classifier', SVC(gamma='auto'))])\n",
    "#в параметры передаем только ядра \n",
    "            param_grid = {'classifier__kernel': ['linear','poly', 'rbf', 'sigmoid']}\n",
    "            X_train, X_test, y_train, y_test = train_test_split(mod_X, y, test_size=0.2)\n",
    "            grid_search = RandomizedSearchCV(clf, param_grid, cv=3)#,verbose=10)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            score = grid_search.score(X_test, y_test)\n",
    "#далее обновляем значения в словаре-по условию что каждый последующий score(test_X, test_y)\n",
    "#сравнивается с предыдущим по принципу-если больше, то максимален\n",
    "            if dict_of_best_params[\"test_data_score:\"]<=score:\n",
    "                dict_of_best_params[\"test_data_score:\"]=score\n",
    "                dict_of_best_params['Preproccess_data:']=step\n",
    "                dict_of_best_params['Category_encoder:']=pipe1     \n",
    "                dict_of_best_params['Scaler:']=pipe2\n",
    "                dict_of_best_params['Kernel:']=grid_search.best_params_['classifier__kernel']\n",
    "            \n",
    "#выводим лучшие параметры            \n",
    "print(dict_of_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры 0.849 достигаются при Category_encoder-WOE, Scaler-StandartScaler, kernel-rbf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь попробуем подобрать С и gamma\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import category_encoders\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, \\\n",
    "    RobustScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "mod_X = converted_data.drop(['class'], axis=1)\n",
    "for feat in not_full_feats:\n",
    "    mod_X[feat] = np.where(mod_X[feat] == '?', '<UNK>', mod_X[feat])\n",
    "categorical = ['workclass','education','marital_status',\n",
    "               'occupation','relationship','race','sex','native-country']\n",
    "pipe1 =  category_encoders.woe.WOEEncoder()\n",
    "pipe2 = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', pipe2, numerical),\n",
    "                    ('cat', pipe1, categorical)])\n",
    "#пайплайн для предобработки и последующей передачи в RandomizedSearchCV\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('classifier', SVC())])\n",
    "param_grid = {'classifier__kernel': ['rbf'],\n",
    "             'classifier__C':[1,0.1],\n",
    "             'classifier__gamma':[0.125,0.13,0.135,0.14]\n",
    "             }\n",
    "X_train, X_test, y_train, y_test = train_test_split(mod_X, y, test_size=0.2)\n",
    "grid_search = RandomizedSearchCV(clf, param_grid, cv=3)#,verbose=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print((\"best score from grid search: %.3f\"\n",
    "                   % grid_search.score(X_test, y_test)))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие параметры:\n",
    "best score from grid search: 0.857  \n",
    "{'classifier__kernel': 'rbf', 'classifier__gamma': 0.135, 'classifier__C': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
